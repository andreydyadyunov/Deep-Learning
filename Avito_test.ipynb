{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Avito_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgdOmKUcdcT-",
        "outputId": "deff2666-208f-4829-c802-2764dfcc1e1d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from string import punctuation\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import roc_auc_score as roc_auc\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQMfP_G2d5-C"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/train.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('content/train.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-2uh1YnfpeU"
      },
      "source": [
        "df = pd.read_csv('content/train.csv/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwGad_nkd2LJ"
      },
      "source": [
        "x_val = pd.read_csv('val.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ7Twhi0eb4t"
      },
      "source": [
        "df['title_description'] = df.title + ' ' + df.description\n",
        "train = df[['title_description', 'category', 'is_bad']]\n",
        "x_val['title_description'] = x_val.title + ' ' + x_val.description\n",
        "test = x_val[['is_bad', 'title_description', 'category']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksp2P5gGemvm"
      },
      "source": [
        "del df\n",
        "del x_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWxoIN9H8ftx"
      },
      "source": [
        "### Кастомный стандартизатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVI5aK8Nf_dS"
      },
      "source": [
        "@tf.keras.utils.register_keras_serializable(package='Custom', name='standart')\n",
        "def standartizer(data):\n",
        "\n",
        "    url = \"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
        "    email = '[\\w\\.-]+@[\\w\\.-]+'\n",
        "    mention = '@\\w+'\n",
        "    phone = '\\d{10}|\\d{3} \\d{3} \\d{2} \\d{2}|\\d{3} \\d{3} \\d{2}-\\d{2}|\\d{3} \\d{3}-\\d{2}-\\d{2}|\\d{3}-\\d{3}-\\d{2}-\\d{2}|\\d{6}|\\d{2}-\\d{2}-\\d{2}|\\d{2} \\d{2} \\d{2}'\n",
        "    stopwords = ' | '.join(r'\\b{}\\b'.format(w) for w in stop_words)\n",
        "    stopwords = re.compile(' | '.join(r'\\b{}\\b'.format(w) for w in stop_words), flags=re.I | re.X).pattern\n",
        "    digits = '[0-9]+'\n",
        "    word_length = r'\\b\\w{1,3}\\b'\n",
        "    \n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                        u\"\\U00002702-\\U000027B0\"\n",
        "                        u\"\\U000024C2-\\U0001F251\"\n",
        "                        \"]+\", flags=re.UNICODE).pattern\n",
        "    \n",
        "    data = tf.strings.lower(data)\n",
        "    data = tf.strings.regex_replace(data, url, 'URL')\n",
        "    data = tf.strings.regex_replace(data, email, 'EMAIL')\n",
        "    data = tf.strings.regex_replace(data, mention, 'MENTION')\n",
        "    data = tf.strings.regex_replace(data, phone, 'PHONE')\n",
        "    data = tf.strings.regex_replace(data, emoji_pattern, '') \n",
        "    data = tf.strings.regex_replace(data, '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twulOwF_8pPq"
      },
      "source": [
        "Модель векторизатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0RaNzArZeq8l"
      },
      "source": [
        "vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=25000, \n",
        "        standardize=standartizer, \n",
        "        output_sequence_length = 1000,\n",
        "        output_mode='int', pad_to_max_tokens=True\n",
        "    )\n",
        "vectorizer.adapt(train.title_description.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxdAecqme9VE"
      },
      "source": [
        "vectorize_layer_model = tf.keras.models.Sequential()\n",
        "vectorize_layer_model.add(tf.keras.Input(shape=(1, ), dtype=tf.string))\n",
        "vectorize_layer_model.add(vectorizer)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGdcon0De_nD",
        "outputId": "d9b85ec4-a889-4c39-f1a0-414d482c7d29"
      },
      "source": [
        "vectorize_layer_model.save('vectorizer_model')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: vectorizer_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixWcKghxfCBe",
        "outputId": "a4c6c664-8f8b-4162-e4a7-16835ec2157f"
      },
      "source": [
        "vector_load = tf.keras.models.load_model('vectorizer_model')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdYKXZjw8wNr"
      },
      "source": [
        "### Архитектура самой модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYQb5juTfIo5"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      \n",
        "        tf.keras.layers.Embedding(input_dim=25000, output_dim=64, input_length=1000),\n",
        "\n",
        "        tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(),\n",
        "\n",
        "        tf.keras.layers.Conv1D(32, 3, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(),\n",
        "\n",
        "        tf.keras.layers.Conv1D(16, 3, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ah0fWxP81__"
      },
      "source": [
        "### Обучаем векторизатор и потом модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5ZM6LEIfJjA"
      },
      "source": [
        "tran = pad_sequences(vector_load.predict(train.title_description).numpy(), maxlen=1000, padding='post')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrgPhxV0fObx",
        "outputId": "ab678dd7-3bfe-4994-f609-8457f59ce16f"
      },
      "source": [
        "model.fit(tran, train.is_bad, batch_size=128, epochs=3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "7692/7692 [==============================] - 333s 39ms/step - loss: 0.2206 - auc: 0.9482\n",
            "Epoch 2/3\n",
            "7692/7692 [==============================] - 300s 39ms/step - loss: 0.1707 - auc: 0.9693\n",
            "Epoch 3/3\n",
            "7692/7692 [==============================] - 300s 39ms/step - loss: 0.1438 - auc: 0.9786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd7deab8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU2-WoGvfPNz",
        "outputId": "a19c21ba-19a4-4a12-dc35-ea6a9b8d8158"
      },
      "source": [
        "model.save('model_finally')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_finally/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD_V9Ldflj1F"
      },
      "source": [
        "model_load = tf.keras.models.load_model('model_finally')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7KFp-sd-8f3"
      },
      "source": [
        "### Проверим качество на валидации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJYJC-Kb9vl3"
      },
      "source": [
        "val_data = pd.read_csv('val.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUBfMXoZ92e3"
      },
      "source": [
        "val_data['title_description'] = val_data.title + ' ' + val_data.description\n",
        "val_data = val_data[['title_description', 'category', 'is_bad']]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIGBnF2U9jc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2705c852-c815-47e2-b390-b321486ff987"
      },
      "source": [
        "aucs = []\n",
        "for category in pd.unique(val_data['category']):\n",
        "        df = val_data[val_data['category'] == category]\n",
        "        descriptions = df['title_description'].values\n",
        "        target = df['is_bad'].values\n",
        "\n",
        "        y_vect = pad_sequences(vector_load.predict(descriptions).numpy(), maxlen=1000, padding='post')\n",
        "        y_pred = model_load.predict(y_vect)\n",
        "        auc = roc_auc(target, y_pred)\n",
        "        print(f'{category} -- {auc}')\n",
        "        aucs.append(auc)\n",
        "print(np.mean(aucs))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Транспорт -- 0.987089027841892\n",
            "Для бизнеса -- 0.8298463550179797\n",
            "Для дома и дачи -- 0.9380185605723277\n",
            "Личные вещи -- 0.8425747070345594\n",
            "Услуги -- 0.910137079031985\n",
            "Бытовая электроника -- 0.950951293759513\n",
            "Недвижимость -- 0.9596301973060386\n",
            "Хобби и отдых -- 0.8845830805842005\n",
            "Работа -- 0.8872397945390647\n",
            "Животные -- 0.927437641723356\n",
            "0.9117507737410918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs3yFRf68Gmu"
      },
      "source": [
        "### Ниже код для сохранения моделей на гугл диск\n",
        "Filename - название, которое будет на гугл диске. Folders_or_files_to_save - соответствующие папке в коллабе\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbgAf59hhq_B",
        "outputId": "72a1d1f5-0471-4e02-d785-92bab8f07a12"
      },
      "source": [
        "#@title save yo data to drive\n",
        "filename = \"model_finally\" #@param {type:\"string\"}\n",
        "folders_or_files_to_save = \"model_finally\" #@param {type:\"string\"}\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "    file_metadata = {\n",
        "    'name': name,\n",
        "    'mimeType': 'application/octet-stream'\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(path, \n",
        "                  mimetype='application/octet-stream',\n",
        "                  resumable=True)\n",
        "\n",
        "    created = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "\n",
        "    print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "    return created\n",
        "\n",
        "\n",
        "extension_zip = \".zip\"\n",
        "\n",
        "zip_file = filename + extension_zip\n",
        "\n",
        "# !rm -rf $zip_file\n",
        "!zip -r $zip_file {folders_or_files_to_save} # FOLDERS TO SAVE INTO ZIP FILE\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "destination_name = zip_file\n",
        "path_to_file = zip_file\n",
        "save_file_to_drive(destination_name, path_to_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: model_finally/ (stored 0%)\n",
            "  adding: model_finally/saved_model.pb (deflated 88%)\n",
            "  adding: model_finally/variables/ (stored 0%)\n",
            "  adding: model_finally/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model_finally/variables/variables.index (deflated 68%)\n",
            "  adding: model_finally/assets/ (stored 0%)\n",
            "  adding: model_finally/keras_metadata.pb (deflated 92%)\n",
            "File ID: 1d_fgMdydWLDfxTdelGGrgLVxXpFoI2pI\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'id': '1d_fgMdydWLDfxTdelGGrgLVxXpFoI2pI'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2XuGK35h1AX",
        "outputId": "a743c465-fbaa-4976-f943-ef2e81458d6b"
      },
      "source": [
        "#@title save yo data to drive\n",
        "filename = \"vectorizer_model\" #@param {type:\"string\"}\n",
        "folders_or_files_to_save = \"vectorizer_model\" #@param {type:\"string\"}\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "    file_metadata = {\n",
        "    'name': name,\n",
        "    'mimeType': 'application/octet-stream'\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(path, \n",
        "                  mimetype='application/octet-stream',\n",
        "                  resumable=True)\n",
        "\n",
        "    created = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "\n",
        "    print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "    return created\n",
        "\n",
        "\n",
        "extension_zip = \".zip\"\n",
        "\n",
        "zip_file = filename + extension_zip\n",
        "\n",
        "# !rm -rf $zip_file\n",
        "!zip -r $zip_file {folders_or_files_to_save} # FOLDERS TO SAVE INTO ZIP FILE\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "destination_name = zip_file\n",
        "path_to_file = zip_file\n",
        "save_file_to_drive(destination_name, path_to_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: vectorizer_model/ (stored 0%)\n",
            "  adding: vectorizer_model/saved_model.pb (deflated 72%)\n",
            "  adding: vectorizer_model/variables/ (stored 0%)\n",
            "  adding: vectorizer_model/variables/variables.data-00000-of-00001 (deflated 44%)\n",
            "  adding: vectorizer_model/variables/variables.index (deflated 20%)\n",
            "  adding: vectorizer_model/assets/ (stored 0%)\n",
            "  adding: vectorizer_model/keras_metadata.pb (deflated 79%)\n",
            "File ID: 1W7qfUJngCwKS0BfxIXXdZS-VOiMNq4XJ\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'id': '1W7qfUJngCwKS0BfxIXXdZS-VOiMNq4XJ'}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}